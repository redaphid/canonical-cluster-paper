doc:
  logo: images/interview-icon.png
  title: Written Interview
  miro: https://miro.com/app/board/uXjVMeJA43k=/
  main:
    - title: Identity and Authorization Technology
      prompts:
      - prompt: Describe your experience with authorization systems, specifically Open Policy Agent and OAuth.
        answers:
        - response: |
            I have extensive, varied experience when it comes to authorization and authentication systems.
            I will give some brief bullet points of my experiences over time with various authorization systems, and then I will give some more detailed examples of my experience with Open Policy Agent and OAuth.

            * The earliest "exotic" auth system I encountered in my career was a strange one called [OACC](http://oaccframework.org). It is a open-source system created by a colleague, and I remember it to be something like RBAC, with some permission delegation mechanism.

            * Next, I worked for Unicon and used [Shiboboleth](https://www.shibboleth.net/) (a SAML-based identity provider)

            * After this, I began work on the open-source Internet of Things platform "Meshblu", and the closed source application that ran on top of it called "Octoblu". Octoblu was later acquired by Citrix.

            #### Experience with Meshblu
            Meshblu is capable of configuring and messaging hardware or software "devices" hardware being things like hue bulbs, or DIY Arduino projects, and software being things like web applications. My team inherited Meshblu with a [permission system](https://meshblu.readme.io/reference/whitelists) that was baked directly in to the json document that represented the configuration of the device. This system was a simple one - arrays of concrete uuids that are allowed to perform certain actions. It was only capable of dealing with concrete entities - no roles, groups, etc. My colleagues and I eventually replaced it with a [more flexible system](https://meshblu.readme.io/reference/whitelists-2-0) that is still very simple and easy to understand.

            In short, it is a 2-dimensional "permission matrix", where the first dimension is the actions that can be taken on a device {broadcast, discover, configure, message}, and the second dimension usually has 2-3 permissions that were relevant to the action domain. Critically, we added an 'as' permission, allowed for impersonation, which makes groups possible without being baked in to the system.

            On top of this, we have many microservices that exist in "userland" with respect to Meshblu; they services could implement different authorization systems on top of Meshblu if necessary or desired. For example, we had a microservice that translated between OAuth and our permission system.

            We had many authn/authz systems of our own to do this permission translation. For example, a microcontroller may need to authenticate via MQTT, the protocol it is using to communicate with Meshblu. Often communications happened over http, and we allowed for basic auth if necessary. Since we had many protocols, I ended up having doing this translation a lot.

            We had many microservices that would "assume the identity" of a device, and bridge the gap between Meshblu and other services, which often required the use of OAuth. In some cases, I remember having to do the "OAuth handshake" between 4 different oauth providers (including at least 1 of ours). It will take me a while to remember the details of this, and I'm trying not to get *too* rambly for the sake of those having to read this :)

            #### The "Totally Naive Services" cluster & Open Policy Agent experience

            I later designed an experimental cluster to be used in environments with complex and unknown-to-us security requirements, potentially including governmental or military applications. The cluster would be deployed in both single-tenant, on-prem environments and multitenant cloud environments. The cluster design factored out multitenancy with respect to the services it contained; e.g. the underlying services did not have a concept of organizations, or really even users (from a security standpoint). I used Open Policy Agent to the point of absurdity when it came to this cluster design, with the expectation that we'd eventually hit a wall of impracticality after which the services inside the cluster would have to become more complex as they became more aware of their environment.

            This approach to cluster development allowed us to build the cluster in parallel to the teams developing the services, and the development roadmaps of these services could be organized such that there was no wasted code if some of the more novel ideas did not work out.

            _aside: I wrote a wrote a Javascript poc that used OPA's ability to return a partially-solved abstract syntax tree from a policy, and then execute it using function composition with [Ramda](https://ramdajs.com/). Should you do this? No. But it was interesting!_

            #### Cluster design from a security standpoint
            Seeing how I now have a captive audience (dear reader), I'll use the cluster as an object lesson in how I design things when in "Research and Development mode", while minimizing risk during the development of production code.
            I am recalling this from memory, and recreating the diagrams, so I may be wrong about some of the details.

        - response: |
            At the highest level, the cluster is divided into 3 concentric circles of trust:

        - response: |
            1. No trust (outside world)
            1. Authentication trust (within cluster)
            1. Authorization trust. "Naive" (within pod)

          figure:
            figure: naive-service-overview
            miro: '3458764548628056239'

        - response: |
            The barriers between these circles were enforced by OPA.
            Outside of the authentication barrier, we are in a no-trust environment.
            Once we pass through the authentication barrier, communications between the services can trust that the request was from who it says it is.
        - response: |
            #### Authentication Barrier
            In the proof of concept, I used Envoy to insert an "Identity" header into the request after the request was validated through whatever mechanism the client wanted to use. We offered a Keycloak instance as an IdP with OIDC capabilities, but we also would accept OIDC credentials from a trusted 3rd party; or many other authentication mechanisms - we followed an adapter pattern for normalizing auth requirements and data, which I'll talk about a little bit later on.

            Regardless of the mechanism used, in the end an OPA policy always gated access to the cluster. The client's authentication data was evaluated against OPA policies, which had the final say. This, like all autoinjected systems in the cluster, could be opted out of via configuration.

            This implementation, however, has a potential vulnerability in that we would need to scrub an "Identity" header off of the incoming request. Since all requests were coming in through the ingress controller that Envoy was manipulating the headers from, in theory this wouldn't be a problem - but I would have rather encapsulated the request in an envelope larger than the request itself. I had learned with Meshblu that separation between data and metadata is very important, especially with regard to security.

            In addition, this header could be manipulated by a malicious service within the cluster. The header solution was good enough for a proof of concept, but further research would be needed to create an envelope for the request that sufficiently separated "userland" requests and cluster metadata. Anyway, that's a mini self-audit of this implementation.

            Past this barrier, the services could trust that the request was from who it said it was, but they could not (yet) trust that the request was authorized to do what it was trying to do.

        - response: |
            #### Authorization Barrier
            After the authentication barrier is passed, any subsequent OPA policy evaluation can assume that the identity presented to the policy for evaluation is accurate, which allows for simple, decoupled policies to govern authorization on a per-service pod basis.

        - response: |
            An OPA service was injected into each Kubernetes pod by default, though the authors of a particular service could override the defaults if they were too onerous. Work was being done on embedding OPA as a plugin to Envoy (also injected by default in Istio)
            Also by default, the OPA service would only do the authorization gating on ingress traffic - though evolutions of this design allowed for OPA to filter egress traffic as well. But we'll get to that later.

        - response: |
            One of the goals of the cluster experiment was to support existing security infrastructure transparently. OPA was used as the only gate for both trust boundaries, but the clients may need information from their existing IdP (identity provider) in order to reason about access control. This entails using data or existing rules from Active Directory, Okta, or various other IdPs within the logic of a policy.

        - response: |
           I accomplished this requirement by making several microservices that used the adapter pattern to ETL (extract,transform,load) any information necessary for policy evaluation from various IdPs to OPA's internal, ephermal datastore.
          figure:
            figure: opa-etl
            miro: '3458764548738949056'
      - prompt: Describe your experience integrating OpenID Connect providers or using OpenID Connect libraries in your projects.
        answer: answer 2
      - prompt: Describe your experience with container technologies such as Docker, LXD and Kubernetes.
        answer: answer 2
    - title: General Software Engineering Experience
      prompts:
      - prompt: Describe your experience integrating OpenID Connect providers or using OpenID Connect libraries in your projects.
        answer: answer 1

  paragraphs:
  thanks_at_the_end: |-
    I am impressed by the context you have provided me during this process.
    I know some people think it's a bad thing to do this kind of work up front - and I've heard muttering on Reddit, etc that these first set of questions are unreasonable - but contextualizing them as a quasi-first-interview makes it seem totally reasonable. In addition, I am equally impressed by the role you play when it comes to finding the right fit for applicants, even if they have applied to the wrong position. I wish other hiring processes were more like this. Anyway, just wanted to let y'all know those thoughts crossed my mind.
    -
